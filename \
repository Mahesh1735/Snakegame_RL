from collections import deque
from DQNAgent import DQNAgent
from snakegame import SnakeEnv
import numpy as np
import h5py
import copy
import time
import os
import keras

NUM_THREADS = '48'

os.environ['MKL_NUM_THREADS'] = NUM_THREADS
os.environ['GOTO_NUM_THREADS'] = NUM_THREADS
os.environ['OMP_NUM_THREADS'] = NUM_THREADS
os.environ['openmp'] = 'True'

env = SnakeEnv(7, 7)
agent = DQNAgent()
episodes = 100010
avg_score=[]
avg_time=[]
avg_score2=[]
avg_time2=[]
avg_score_greedy = []
avg_time_greedy = []

output_filename = "trained_models3/output.txt"
tim = time.time()
epsilon_copy = None
show_episode = False
counter = 11

for e in range(episodes):
        state = env.reset()
        for time_t in range(400):
            state = env.getCurrentState()
            action = agent.act(env.state)
            next_state, reward, done = env.step(action)
            next_state = env.getCurrentState()
            #print("Step: {}", time_t)
            #print(state, next_state)
            agent.remember(state, action, reward, next_state, done)
            # make next_state the new current state for the next frame.
            state = next_state
            # done becomes True when the game ends

            if e%100 == 0 or show_episode:
                print(agent.model.predict(env.getCurrentState().reshape(1, 1, 7, 7)))
                print(state)

            if env.done:
                # print the score and break out of the loop
                avg_score.append(len(env.snake)-2)
                avg_time.append(time_t)
                avg_score2.append(len(env.snake) - 2)
                avg_time2.append(time_t)
                avg_score_greedy.append(len(env.snake) - 2)
                avg_time_greedy.append(time_t)
                break
        # train the agent with the experience of the episode
        
        agent.replay(min(48, len(agent.memory)))
        if e%100==0:
            print("episode: {}/{}, average score: {}, average time: {}, epsilon: {}"
                      .format(e, episodes, np.array(avg_score).mean(), np.array(avg_time).mean(), agent.epsilon))
            avg_score=[]
            avg_time=[]
        if e%1000==0:
            agent.model.save("trained_models3/trained_model_%d.h5" %(e))
            with open(output_filename, "a") as outfile:
                outfile.write("\n\nepisode: {}/{}, average score: {}, average time: {}, epsilon: {}"
                                 .format(e, episodes, np.array(avg_score2).mean(), np.array(avg_time2).mean(), agent.epsilon))
                outfile.write("\n\n GREEDY POLICY EVALUATION: \n")
                avg_score2=[]
                avg_time2=[]
                avg_score_greedy = []
                avg_time_greedy = []
            
            epsilon_copy = agent.epsilon
            counter = 0
            agent.epsilon = 0
            agent.target_network = keras.models.clone_model(agent.model, agent.model.get_weights())
        
        if counter <= 10:
            show_episode = True
            counter += 1
        
        if counter == 10:
            agent.epsilon = epsilon_copy
            counter = 11
            show_episode = False
            with open(output_filename, "a") as outfile:
                outfile.write("\n\nepisode: {}/{}, average score: {}, average time: {}, epsilon: {}"
                               .format(e, episodes, np.array(avg_score_greedy).mean(), np.array(avg_time_greedy).mean(), agent.epsilon))

print(time.time()-tim)
agent.model.save("trained_models3/trained_model_final.h5")
